dino:
  head_n_prototypes: 131072
  head_bottleneck_dim: 384
  do_kde: True
  kde_loss_weight: .05
  koleo_loss_weight: 0
  do_koleo: False
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
    - 0.1
    - 0.45
  separate_head: true
  head_n_prototypes: 131072
train:
  sample_list_path: /data/TCGA/sample_dataset_ablation.txt # gives paths to svs files for data loading if streaming_from_hf=False
  streaming_from_hf: true
  streaming_dataset_path: medarc/TCGA-12K-parquet
  batch_size_per_gpu: 256 # assuming 1-gpu; if training with full 8-gpu node decrease to 32 to keep same global batch size across ablations
  centering: sinkhorn_knopp
  use_pretrained: True
  OFFICIAL_EPOCH_LENGTH: 500
  num_workers: 4
  skip_checkpointer: true
student:
  arch: vit_small
  patch_size: 14
  drop_path_rate: 0.1
  ffn_layer: mlp
  block_chunks: 4
  num_register_tokens: 4
  layerscale: 1.0
  interpolate_antialias: True
  interpolate_offset: 0.0
teacher:
  momentum_teacher: 0.994
  warmup_teacher_temp: 0.04
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 2000
  early_stop: 50
  weight_decay_end: 0.2
  base_lr: 8.0e-4
  warmup_epochs: 3
  layerwise_decay: 1.0
  freeze_last_layer_epochs: 1
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 4
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 98
evaluation:
  eval_period_iterations: 2500 # save checkpoint every x iterations

  # bach_root: /data/eva-data/bach # assuming you want continuous Bach validation; change to abs path to folder containing "ICIAR2018_BACH_Challenge"

  bach_root: null  # Set to path of ICIAR2018_BACH_Challenge folder if you have it
  breakhis_root: null  # Set to path of BreakHis dataset if you have it
  pcam_root: null  # Set to path of PCam dataset if you have it
